## Ali  
Originally published: 2013-02-17 12:54:44  
Last updated: 2013-02-17 12:54:44  
Author: Alireza Hosseini  
  
## {{{ http://code.activestate.com/recipes/578439/ (r1)\n#Just a try using the thread modules.\n\n\nimport urllib as ul\nimport bs4 as bs\nimport urlparse as up\nimport re as re \nimport os.path as op \nimport Queue as que\nimport time\nimport threading\n\npat = re.compile('.*[\\d]{4,7}.*')\n\ncount=0\n\nclass dldfile(threading.Thread):\n    def __init__(self,qu1):\n        threading.Thread.__init__(self)\n        self.qu1=qu1\n        self.ad='download/1/'\n        \n    def run(self):\n        try:\n            url,filename=self.qu1.get()\n            url =url+self.ad             #comment this line in case need to download whole web page instead of recipe ONLY...\n            ul.urlretrieve(url,filename)\n            global count\n        except:\n            print " RE-TRYING ",\n            count= count - 1\n            self.qu1.put((url,filename))\n            self.run()\n        finally:\n            count= count +1\n            print str(count)+"("+str( threading.activeCount())  +")",filename\n            self.qu1.task_done()\n\nclass dload(threading.Thread ):\n    def __init__(self,qu,url = "http://code.activestate.com/recipes/langs/python/?page=" ):\n        threading.Thread.__init__(self)\n        self.url=  url\n        self.q =que.Queue()\n        self.qu=qu\n        \n    def run(self):\n        ind=self.qu.get()\n        url=self.url+str(ind)\n        soup =bs.BeautifulSoup(''.join( ul.urlopen(url).readlines() ))\n        bu = up.urlsplit(self.url)\n        print 'started with the ' ,str(url).split('/')[-1],\n        for i in  soup.find_all(attrs = { "class" : "recipe-title"}):\n            sp = up.urlsplit(i.a.get('href'))\n            path = sp.path\n            print path\n            if re.search(pat, path):\n                path = bu.scheme+'://'+bu.netloc+path\n                filename = str(path).split('/')[-2]\n                filename = op.join(op.abspath(op.curdir),filename+'.py') # recipe will be stored in given location\n#                filename = op.join(op.abspath(op.curdir),filename+'.html')\n#uncomment the above line if downloading the web page for teh recipe\n                print path\n                self.q.put((path,filename))\n        self.fetch_data()\n        time.sleep(1)\n        self.qu.task_done()\n        self.q.join()\n        print 'done with the ' ,str(url).split('/')[-1],\n        \n    def fetch_data(self):\n        Que1 = que.Queue()\n        minitask =10\n        while not self.q.empty():\n            for i in range(minitask):\n                x = dldfile(Que1)\n                x.setDaemon(True)\n                x.start()\n            for j in range(minitask):\n                Que1.put(self.q.get())\n            Que1.join()\n            del x\n\nif __name__ =='__main__':\n    task=5\n    Que = que.Queue()\n    for k in range(1,190,task):  # no. of pages included under the python tag.  188 is current count and 3700+ python recipes\n        print "\\n PAGE # : {0} \\t \\nDeploying  Fresh threads\\n".format(k)\n        for i in range(task):\n            t = dload(Que)\n            t.start()\n        for j in range(task):\n            Que.put(k+j)\n        Que.join()\n        Que.queue.clear()\n        del t\n        print "DONE\\n"\n        time.sleep(2)\n    del Que\n    print "Our buisness finished"\n## end of http://code.activestate.com/recipes/578439/ }}}\n